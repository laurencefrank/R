---
title: "Practical D - Solutions"
author: "Gerko Vink"
date: "Statistical Programming with R"
output: html_document
---


---

#### Exercises

---

It is always wise to fix the random seed. I often use a seed value of `123`:
```{r}
set.seed(123)
```
at the top of my document. This ensures that all calculations in my documents are exactly reproducible. This is because the random number generator in `R` will take its origin from the specified seed value. Every subsequent random process advance the random generation by one step. When we specify a seed value we can replicate the exact chain of random processes. This is an extremely useful tool.

When an `R` instance is started, there is initially no seed. In that case, `R` will create one from the current time and process ID. Hence, different sessions will give different results when random numbers are involved. When you store a workspace and reopen it, you will continue from the seed specified within the workspace. 

---

1. **Fix the random seed to `123`**
```{r}
set.seed(seed = 123)
```
or simply
```{r}
set.seed(123)
```

The random number generator is now fixed to value `123`. We can now ensure that our data generation process is exactly reproducible on every machine using `R` around the world. 

---

#### Drawing random values

---

2. **Draw 10 values from a standard normal distribution and store the values in an object called `draw1`**.
```{r}
draw1 <- rnorm(n = 10)
```
The call `rnorm(n = 10)` results in a draw of 10 values from a standard normal distribution, a distribution with mean zero and variance equal to 1. Drawing from a standard normal distribution is the default in `rnorm` because the default function arguments for `rnorm()` specify:
```{r}
args(rnorm)
```
We can see that by default, values a drawn with `mean = 0` and `sd = 1`. Unless we specify other values for the mean and standard deviation, the defaults will be used. 

---

3. **Verify that the means and variances for object `draw1` are indeed conform to the default values for `mean` and `sd` of the function `rnorm()`**
```{r}
mean(draw1)
sd(draw1)
```
The means and variances are close, but not equal to the default values. However, we've only drawn 10 values from a theoretical distribution. It is statistically not reasonable to expect that a single draw of 10 values will result in an unbiased estimate of the (infinitely large) population parameters.

---

4. **Draw 1000 values from a standard normal distribution and store the values in an object called `draw2`**.
```{r}
draw2 <- rnorm(n=1000)
```
 

---

5. **Determine which object has less bias; `draw1` or `draw2`**
```{r}
means <- c(0, mean(draw1), mean(draw2))
sds <- c(1, sd(draw1), sd(draw2))
n <- c(Inf, 10, 1000)
result <- data.frame(n=n, mean=means, sd=sds)
row.names(result) <- c("population", "draw1", "draw2")
result
```
We have now created a `data.frame` with the results. Perhaps this data frame becomes easier to read with some rounding:
```{r}
round(result, 3)
```
It is clear that the larger sample size will, in general, yield less bias. However, the bias we obtain is depends on the chosen random seed. For example, if we repeat the above process with `set.seed(125)`, we obtain completely different results:
```{r}
set.seed(125)
draw1b <- rnorm(10)
draw2b <- rnorm(1000)
means <- c(0, mean(draw1b), mean(draw2b))
sds <- c(1, sd(draw1b), sd(draw2b))
result <- data.frame(n=n, mean=means, sd=sds)
row.names(result) <- c("population", "draw1 (seed=125)", "draw2 (seed=125)")
round(result, 3)
```
Now `draw2` has a larger absolute bias from the mean, despite its larger sample size. Note that I renamed the objects to `draw1b` and `draw2b` because otherwise I would overwrite `draw1` and `draw2`. Overwriting these objects would be inefficient, because we will use these objects later on in this exercise.  If, by accident we would have overwritten these objects, we can simply obtain them again by re-fixing the random seed and parsing the exact same function calls. Also note that I do not recreate object `n` as it has not changed. I can simply re-use the object `n` that is already in our `Global Environment`. 

---

The lesson so far is: When you fix your random seed, do not forget that your results are dependent on this random seed. It may be the case that results you obtain are a mere fluke: extremely rare, but obtained because you use a random seed. It would be nice to automate any random number process with different seeds to obtain the sampling distribution of estimates. This we will do on Thursday and Friday when we consider resampling techniques like cross-validation and bootstrapping. 

---

In the previous exercise we have changed the random seed to `125`. 

---

6. **Re-fix the random seed to `123`**
```{r}
set.seed(123)
```

---

7. **Draw objects `draw1` and `draw2` again, but name them `draw3` and `draw4`, respectively.**
```{r}
draw3 <- rnorm(n=10)
draw4 <- rnorm(n=1000)
```

---

8. **Draw object `draw5`: 22 values from a normal distribution with `mean = 8` and `variance = 144`.**
```{r}
draw5 <- rnorm(22, 8, sqrt(144)) #square root of 144 
```
Function `rnorm()` takes the standard deviation $\sigma$, not the variance $\sigma^2$. Hence we take the square root of the variance to obtain the standard deviation cf.

\[\sigma=\sqrt{\sigma^2} = \sqrt{144} = 12\]

---

9. **Verify if object `draw1` is equal to `draw3` and if object `draw2` is equal to `draw4`.**
```{r}
all.equal(draw1, draw3)
all.equal(draw2, draw4)
```
The objects are indeed equal because they originated in an identical order since the same random seed was specified. In other words, `draw1` and `draw3` were generated in random step 1 since `set.seed(123)` and `draw2` and `draw4` were both generated in step 2 since `set.seed(123)`. If we would have reversed the order in which these objects were generated, then the objects would not be equal. For example:
```{r}
set.seed(123)
draw4 <- rnorm(1000)
draw3 <- rnorm(10)
all.equal(draw1, draw3)
all.equal(draw2, draw4)
```
Because the objects are not equal, mean differences are automatically printed by function `all.equal()`.

**Fun fact:** the first 10 cases in `draw1` and `draw4` are equal:
```{r}
cbind(draw1[1:10], draw4[1:10])
```
and if we recreate `draw5`, the results are also equal. 
```{r}
draw5b <- rnorm(22, 8, sqrt(144))
all.equal(draw5, draw5b)
```
This is because these values and objects follow the same steps since `set.seed(123)`. The first 10 cases in `draw1` and `draw4` both stem from the first step since `set.seed(123)` and generating `draw5` and `draw5b` has been the third random step since `set.seed(123)` in both random chains. 

---

10. **Draw 1000 values from the following distributions and inspect them with `summary()`**

- a normal distribution with `mean = 50` and `sd = 20`, 
- a t-distribution with `df = 11` degrees of freedom,
- a uniform distribution with minimum `min = 5` and maximum `max = 6`,
- a binomial distribution with `size = 1` trials and `prob = .8` probablity if success on each trial,
- an F-distribution with `df1 = 1` and `df2 = 2` degrees of freedom,
- a poisson distribution with `lambda = 5` as the mean. 

First, 
```{r}
draw.norm <- rnorm(1000, mean = 50, sd = 20)
draw.t <- rt(1000, df = 11)
draw.unif <- runif(1000, min = 5, max = 6)
draw.binom <- rbinom(1000, size = 1, prob = .8)
draw.F <- rf(1000, df1 = 1, df2 = 2)
draw.pois <- rpois(1000, lambda = 5)
```
It may ease interpretation to create a `data.frame` from these results and call summary on the data frame. 
```{r}
data <- data.frame(normal = draw.norm, 
                   t = draw.t, 
                   uniform = draw.unif, 
                   binomial = draw.binom,
                   Fdistr = draw.F,
                   poisson = draw.pois)
summary(data)
```

---

11. **Plot histograms for the generated values from exercise 10 to inspect the shape of the respective distributions. Use `breaks = 25` for the number of breakpoints in the histogram **
```{r}
hist(draw.norm, breaks = 25)
hist(draw.t, breaks = 25)
hist(draw.unif, breaks = 25)
hist(draw.binom, breaks = 25)
hist(draw.F, breaks = 25)
hist(draw.pois, breaks = 25)
```


12. **Draw two variables of size `1000` from a multivariate normal distribution, both with mean `5` and variance `1` and make sure that they correlate $\rho = .8$.**

```{r}
#you need function rmvnorm from package mvtnorm
sigma <- matrix(c(1, .8, .8, 1), nrow = 2, ncol = 2) #variance/covariance matrix
data <- mvtnorm::rmvnorm(n = 1000, sigma = sigma, mean = c(5, 5))
colMeans(data)
var(data)
```


---

End of Practical
