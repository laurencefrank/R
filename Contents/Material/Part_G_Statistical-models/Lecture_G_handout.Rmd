---
title: "Lecture G - Statistical Models"
author: "Gerko Vink"
date: "Statistical Programming with R"
output: 
  html_document:
    toc: true
    toc_depth: 5
    toc_float: true
    number_sections: false
---
<style type="text/css">

body{ /* Normal  */
      font-size: 12px;
  }
td {  /* Table  */
  font-size: 12px;
}
h1.title {
  font-size: 18px;
  color: DarkBlue;
}
h1 { /* Header 1 */
  font-size: 18px;
}
h2 { /* Header 2 */
    font-size: 18px;
}
h3 { /* Header 3 */
  font-size: 18px;
}
code.r{ /* Code block */
    font-size: 12px;
}
pre { /* Code block - determines code spacing between lines */
    font-size: 14px;
}
</style>

---



## I use the following package in this lecture
```{r message=FALSE}
library(magrittr) #for pipes
library(MASS)     #for the cats and bacteria data
library(mice)     #for the boys data
```

### New functions

- `lm()` to run linear models


```{r echo=FALSE}
set.seed(123)
```

# Statistical models

## Statistical model

The mathematical formulation of relationship between variables can be written as

\[
\mbox{observed}=\mbox{predicted}+\mbox{error}
\]

or (for the greek people) in notation as
\[y=\mu+\varepsilon\]

where

-   $\mu$ (mean) is the part of $Y$ that is explained by model 
-  $\varepsilon$ (residual) is the part of $Y$ that is not explained by model 


## A simple example
Regression model:

-  Model individual age from weight

\[
\text{age}_i=\alpha+\beta\cdot{\text{weight}}_i+\varepsilon_i
\]

where

-  $\alpha+\beta{x}_i$ is the mean of `age`, $y$, conditional on `weight`, $x$.
-  $\varepsilon_i$ is random variation 

## The linear model

The function `lm()` is a base function in `R` and allows you to pose a variety of linear models. 

```{r}
args(lm)
```

If we want to know what these arguments do we can ask R:

```{r, eval=FALSE}
?lm
```

This will open a help page on the `lm()` function.

## Continuous predictors {.smaller}
To obtain a linear model with a main effect for `wgt`, we formulate $age\sim wgt$ 
```{r warning=FALSE, message = FALSE}
fit <- boys %$%
  lm(age ~ wgt)
fit
```

## Continuous predictors: more detail {.smaller}
```{r}
fit %>% summary
```

## Continuous predictors
To obtain a linear model with just main effects for `wgt` and `hgt`, we formulate $age\sim wgt + hgt$ 
```{r}
require(mice)
fit <- boys %$%
  lm(age ~ wgt + hgt)
fit
```

## Continuous predictors: more detail {.smaller}
```{r}
fit %>% summary
```

## Continuous predictors: interaction effects
To predict $age$ from $wgt$, $hgt$ and the interaction $wgt*hgt$ we formulate $age\sim wgt * hgt$
```{r}
fit <- boys %$% lm(age ~ wgt * hgt)
fit
```

##  and with more detail {.smaller}
```{r}
fit %>% summary
```

## Categorical predictors in the linear model
If a categorical variable is entered into function `lm()`, it is automatically converted to a dummy set in `R`. The first level is always taken as the reference category. If we want another reference category we can use the function `relevel()` to change this.

```{r}
fit <- boys %$% lm(age ~ reg)
```

##  and again with more detail {.smaller}
```{r}
fit %>% summary
```

## Components of the linear model {.smaller}
```{r}
names(fit) # the names of the list with output objects
fit$coef  # show the estimated coefficients
coef(fit) # alternative
```

# Distributions


## Distributions
Distributions and models for the random component 

-  Normal distributions

    -  Linear model
    -  error distribution is normal

-  Discrete distributions (counts)

    -  Bernoulli, Binomial or Poisson model
    -  error distribution not normal

-  Other continuous distributions 

    -  Uniform, exponential 
    -  error distribution not normal

# Discrete distributions

## Binomial distribution {.smaller}

Probability of $y$ successes in $n$ trials with probability of success $\pi$

\[
P(y|n,\pi)={n\choose y}\pi^y(1-\pi)^{(n-y)}
\]

For $n=5$ trials:
```{r echo=FALSE, fig.height=4}
par(mfrow=c(1,2), bg = NA)
y <- factor(0:5)
x <- 0:5
barplot(dbinom(x,5,.1),ylim=c(0,.6),names.arg=y,ylab="P(Y=y)",xlab="y")
text(5,.5,expression(paste(pi," = 0.1")))
barplot(dbinom(x,5,.5),ylim=c(0,.6),names.arg=y,ylab="P(Y=y)",xlab="y")
text(5,.5,expression(paste(pi," = 0.5")))
```

## Code that generates plot of previous slide
```{r eval=FALSE, fig.height=4}
par(mfrow=c(1,2), bg = NA)
y <- factor(0:5)
x <- 0:5
barplot(dbinom(x,5,.1),ylim=c(0,.6),names.arg=y,ylab="P(Y=y)",xlab="y")
text(5,.5,expression(paste(pi," = 0.1")))
barplot(dbinom(x,5,.5),ylim=c(0,.6),names.arg=y,ylab="P(Y=y)",xlab="y")
text(5,.5,expression(paste(pi," = 0.5")))
```

## Poisson distribution {.smaller}
The probability of $y$ events within a time period (e.g. number of earthquakes in a year)
\[
P(y|\lambda)=\frac{e^{-\lambda}\lambda^y}{y!}, \text{where } lambda=\text{rate parameter}
\]
```{r echo=FALSE, fig.height=4}
par(mfrow = c(1, 3), bg = NA)
y <- factor(0:5)
x <- 0:5
barplot(dpois(x, .5), ylim = c(0, .6), names.arg = y, 
        ylab = "P(Y=y)", xlab = "y")
text(5, .5, expression(paste(lambda, " = 0.5")))
barplot(dpois(x, 1), 
        ylim = c(0, .6), 
        names.arg = y, 
        ylab = "P(Y=y)", 
        xlab = "y")
text(5, .5, expression(paste(lambda, " = 1")))
barplot(dpois(x, 2), ylim = c(0, .6), names.arg = y, 
        ylab = "P(Y = y)",xlab="y")
text(5,.5,expression(paste(lambda," = 2")))
```

## Code that generates plot of previous slide{.smaller}
```{r eval=FALSE, fig.height=4}
par(mfrow = c(1, 3), bg = NA)
y <- factor(0:5)
x <- 0:5
barplot(dpois(x, .5), 
        ylim = c(0, .6), 
        names.arg = y, 
        ylab = "P(Y=y)", 
        xlab = "y")
text(5, .5, expression(paste(lambda, " = 0.5")))
barplot(dpois(x, 1), 
        ylim = c(0, .6), 
        names.arg = y, 
        ylab = "P(Y=y)", 
        xlab = "y")
text(5, .5, expression(paste(lambda, " = 1")))
barplot(dpois(x, 2), 
        ylim = c(0, .6), 
        names.arg = y, 
        ylab = "P(Y = y)",
        xlab="y")
text(5,.5,expression(paste(lambda," = 2")))
```

# Continuous distributions
## Normal distribution: pdf en cdf {.smaller}
The probability density function (pdf): 
```{r fig.height=4}
par(mfrow=c(1,2), bg=NA)
curve(dnorm(x,0,1),xlim=c(-3,3),ylab="f(x)",main='') 
curve(pnorm(x,0,1),xlim=c(-3,3),ylab="F(X < x)",main='')
```

## Exponential distribution

-  Waiting times (e.g. time until occurrence eartquake)
\[
f(t|\lambda)=\lambda{e}^{-\lambda{t}}
\]

```{r echo = FALSE, fig.height=4}
par(mfrow=c(1,2), bg = NA)
curve(dexp(x,2),from=0, to=5,xlab="t",ylab="f(t)",col="red",main='') 
curve(dexp(x,.5),from=0, to=5,main='',col="blue",add=TRUE) 
text(.8,1.8,expression(paste(lambda," = 2")),col="red")
text(4,0.25,expression(paste(lambda," = 0.5")),col="blue")
curve(pexp(x,2),from=0, to=5,xlab="t",ylab="F(T < t)",main='',col="red")
curve(pexp(x,.5),from=0, to=5,main='',col="blue",add=TRUE)
text(1.5,.8,expression(paste(lambda," = 2")),col="red")
text(2.3,0.5,expression(paste(lambda," = 0.5")),col="blue")
```

# Some more modeling

## Performing a t-test
```{r}
cats %$% t.test(Hwt ~ Sex)
```

## Performing a chi-square test {.smaller}

```{r}
bacteria %>% head(n=8)
```

Column `y`: 

* `n`: Disease absent. 
* `y`: Disease present.

Column `ap`: 

* `a`: Active medicine. 
* `p`: Placebo.


## Performing a chi-square test
```{r}
bacteria %$% table(ap, y)
```
```{r}
x2.table <- table(bacteria$ap, bacteria$y)
x2.table <- cbind(x2.table, rowSums(x2.table))
rbind(x2.table, colSums(x2.table))
```

## chi-square tests

$$\chi^2 = \sum \frac{(O - E)^2}{E}$$

- Observed: 
```{r echo = FALSE}
rbind(x2.table, colSums(x2.table))
```

- Expected:

```{r echo = FALSE}
bacteria %$% chisq.test(ap, y)$expected
```

## Performing a chi-square test
```{r}
prop.table(table(bacteria$ap, bacteria$y), margin = 1)
```

* In the treatment condition, 1/4 is free of disease. 

* In the placebo condition 1/8 is free of the disease. 

Should we assume this means the medicine works?

## Performing a chi-square test
```{r}
bacteria %$% chisq.test(ap, y)
```
or the other way around
```{r}
bacteria %$% chisq.test(y, ap)
```

## Or, equivalently:
```{r}
bacteria %$% table(ap, y) %>% chisq.test
```


## Visualizing this

```{r, dev.args = list(bg = 'transparent')}
bacteria %$% table(y, ap) %>% plot
```

## Visualizing this {.smaller}

```{r fig.height=4.5, dev.args = list(bg = 'transparent')}
barplot(table(bacteria$y, bacteria$ap), 
        beside = TRUE, 
        legend = c("No infection", "Infection"), 
        col = c("blue", "orange"),
        args.legend = list(x=4.5, y=80))
```

## Fisher's exact test {.smaller}

With small expected cell frequencies (roughly if any are below 5), we should use Fishers exact test.

```{r}
short <- bacteria %>%
  subset(week <= 2) %$%
  table(y, ap)
short
```


## Fisher's exact test

```{r}
short %>% chisq.test
```


## Fisher's exact test

```{r warning=TRUE}
#fisher.test(table(short$y, short$ap))
short %>%
  fisher.test
```

What do we conclude?

## Visualizing this

```{r, dev.args = list(bg = 'transparent')}
plot(short)
```

## Visualizing this

```{r fig.height=4, dev.args = list(bg = 'transparent')}
barplot(short, 
        beside = TRUE, 
        legend = c("No infection", "Infection"), 
        col = c("blue", "orange"),
        args.legend = list(x=4.5, y=40))
```


